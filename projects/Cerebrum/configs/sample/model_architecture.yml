model_architecture:
    random_seed: 42  # Random seed for deterministic random parameters
    n_levels: 4  # Number of levels of the model (Each level except the lowest one has subneurons)
    neuron_activity_control:
        goal: 0.1  # Target activity level for neurons (0-1, choosing a high value can cause CPU overload, depending on the numnber of levels)
        upward_effect:
            force: 0.2  # Force to increase the activity of neurons when goal is exceeded (0-1)
            easing: 0.5  # Easing factor for the upward force (0-1)
        downward_effect:
            force: 0.2  # Force to decrease the activity of neurons when goal is not reached (0-1)
            easing: 0.4  # Easing factor for the downward force (0-1)
    relay_neuron:
        transmission:
            synaptic_delay:
                min: 5  # Minimum delay for transmitting information between neurons (milliseconds)
                max: 20  # Maximum delay for transmitting information between neurons (milliseconds)
            max_message_length: 16  # Maximum length of messages transmitted between neurons (# of words)
            synaptic_transformer: # Transformer model for deciding synaptic delay and whether to transmit to neuron or not
                types: # List of transformer models to randomly select from (DistilBERT/TinyBERT/ALBERT/T5-Small/GPT2-Small)
                    - DistilBERT
                    - T5-Small
                weights: # Frequencies for selecting each transformer model
                    - 1  # DistilBERT
                    - 1  # T5-Small
        memory_unit:
            capacity: 1024  # Maximum memory storage capacity for each neuron (# of characters)
            max_append_length: 5  # Maximum length of summary to append to memory for each neuron (# of words)
            memory_transformer: # Tranformer model for summarizing messages to append to memory
                types: # List of transformer models to randomly select from (DistilBERT/TinyBERT/ALBERT/T5-Small/GPT2-Small)
                    - DistilBERT
                    - T5-Small
                weights: # Frequencies for selecting each transformer model
                    - 1  # DistilBERT
                    - 1  # T5-Small
    base_neuron:
        base_transformer: # Transformer model for transforming base responses
            types: # List of transformer models to randomly select from (GPT2/BERT/RoBERTA/T5/XLNET/BART)
                - GPT2
                - BERT
                - RoBERTA
                - T5
                - XLNET
                - BART
            weights: # Frequencies for selecting each transformer model
                - 5  # GPT2
                - 5  # BERT
                - 2  # RoBERTA
                - 2  # T5
                - 2  # XLNET
                - 2  # BART
    response_neuron:
        confidence: 0.5 # Minimum confidence level to give a response (0-1)
        timeout: 20 # Timeout before giving most recent response (seconds)
        discriminator_transformer: GPT2  # Transformer model for discriminating between responses (GPT2/BERT/RoBERTA/T5/XLNET/BART)